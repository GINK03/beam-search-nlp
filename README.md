# Generic-N-Gram Markov Chaine

## Markov Chaineを実装する

## 理論
理論については様々な解釈が散在しており、あまり、適切な文献がどれなのかわからなかったのですが、[英語のWikiepediaの記述](https://en.wikipedia.org/wiki/Markov_chain)をベースに行なっています 

1. N階マルコフ連鎖と呼ばれるもので実装していまして、3つ前までの携帯素から次の単語の確率分布を生成します  

2. 確率分布に従う形で、一つの出力確率として採択して、文章に続く文字とします。

3. 1に戻ります

## Requirements(必要用件)
- Python3
- nvme(高速なディスクでないとKVSがパフォーマンスを発揮できませんが、実行だけなら必要ないかも)
- leveldb(確率分布を保存するKVS)
- plyvel(leveldbのpythonラッパー)
- numpy
- MeCab(形態素解析機)
- メモリできるだけたくさん
- コーパス(600万テキストほど)

今回使用したデータセットだけなら、[minioというサーバで公開](http://121.2.69.245:10001/minio/markov-chaine-data/)します  

## 学習

**128GBのメモリでも足りなかったので、苦肉の策で、メモリを使わずにKVSをhashmapのように使うことで、メモリを省略しています**  

#### 分かち書きしてコーパスを形態素粒度に変換する  
```console
$ python3 prepare.py --wakati
```

#### ngramの特徴量を抽出し、発生頻度をカウントします(要KVSと時間)
```console
$ python3 prepare.py --term_chaine
```

#### 出現頻度から確率分布を作成して、モデルを統合します
```console
$ python3 prepare.py --numpy
$ python3 prepare.py --wrapup
```

## 予想

**初期値を適当にハードコードで与えていますが、任意の文字を与えることもできますが、KVSのキーに入っている必要があります**  

```console
$ python3 prepare.py --sample
```

#### Sample1
```console
選手 が スタメン に 名 を 刻ん だ 。 「 僕ら は ピカソ も 北斎 も ゴーギャン も 教科書 で 見 た 感じ で 、 反応 が すぐ に 売上 高 1899 億 円 （ 同 2 . 41 倍 ） に 引き上げ て も 不思議 で は ない という 司法 の 判断 を 加え ず に 、 コメント 欄 に 「 泥棒 」 という 文字 は 非常 に 低く なり つつ ある わけ です ね 。 <EOS>
```

### Sample2
```console
社長 に 就任 し た 小松 弥生 教育 長 など が 挨拶 を する という の は 、 悪質 コン サル 問題 に 対応 する 」 と つぶやい て いる 。 <EOS>
```

### Sample3
```console
社長 に 就任 し た 小松 弥生 教育 長 など が 挨拶 を する という の は 、 悪質 コン サル 問題 に 対応 する 」 と つぶやい て いる 。 <EOS>
```

### Sample4
```console
あと は インパネ に ある 操作 ボタン を なくし たり と 、 大手 企業 と も 呼ば れる ） を 舞台 化 し て おり ます 。 よく 『 洗濯 物 を 素早く 乾かす に は 、2 種類 の ケース サイズ を 用意 し 、 全 世界 で 1000 万 増やす ! 庶民 の ため の Apple Watch から ヘッド フォン へ 転送 さ れ ない 旨 、 その 理由 の 1 つ で Telegram が ブロック さ れ た と 言わ れ おり 、 経 産 省 が アブダビ 支援 に 力 を 入れ て いる 20 代 から 40 代 で 太もも 前 の 大腿 四 頭 筋 は 10 ％ そこそこ です 。 日本 の 広告 も すっかり 普通 の こと で 驚い て いる 。 <EOS>
```


